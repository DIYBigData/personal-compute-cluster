# performance optimizations
spark.serializer                org.apache.spark.serializer.KryoSerializer
spark.default.parallelism       200
spark.sql.shuffle.partitions    200

# worker node / executor set up
# expecting a worker with 12 cores and 56g of memory
spark.executor.memory           50g
spark.executor.cores            12
spark.executor.extraJavaOptions -XX:+UseG1GC

# driver configurations
spark.driver.memory             6g
spark.driver.memoryOverhead	2g
spark.driver.cores              2
spark.driver.extraJavaOptions -XX:+UseG1GC


# operational configurations
spark.logConf                   true
spark.worker.cleanup.enabled    true

# This setting is to tell the class loaders in Spark that they
# only need to load the QFS access libraries once
spark.sql.hive.metastore.sharedPrefixes         com.quantcast.qfs

# Set up retention of Spark events to enable the history server.
# The configured directory needs to be created prior to launching
# Spark master.
spark.eventLog.enabled              true
spark.eventLog.dir                  qfs:///history/spark-event/
spark.history.fs.logDirectory       qfs:///history/spark-event/
spark.history.fs.cleaner.maxAge     30d

# Configure QFS here rather than in core-site.xml
spark.hadoop.fs.qfs.impl            com.quantcast.qfs.hadoop.QuantcastFileSystem2
spark.hadoop.fs.defaultFS           qfs://qfs-master:20000
spark.hadoop.fs.qfs.metaServerHost  qfs-master
spark.hadoop.fs.qfs.metaServerPort  20000

# this spark.hadoop.fs.qfs.createParams	configure causes files written by Spark to
# QFS to be 2x replicated  rather than using Reed-Solomon encoding. If you have at
# least 9 chunkservers, remove this configuration to instead use Reed-Solomon encoding.
spark.hadoop.fs.qfs.createParams    2
